{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gui27943dYrI"
      },
      "source": [
        "# Transfomer for time series data\n",
        "\n",
        "## Objectives of this Lab\n",
        "\n",
        "- Develop an understanding of the fundamental concepts behind Transformers and implement a basic version.\n",
        "- Gain an introductory understanding of applications of deep learning in finance.\n",
        "- Assess and reinforce your existing knowledge of deep learning.\n",
        "- Explore the potential to apply these skills effectivelyâ€”on the journey to becoming an expert (and maybe... wealthy). ðŸš€\n",
        "\n",
        "\n",
        "In this lab, we aim to build a model capable of predicting trends in stock values, laying the groundwork for a potential trading bot. To achieve this, we will leverage the Transformer Encoder, which is well-suited for capturing complex temporal dependencies in financial data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93IbxoVEdYrK"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install wandb\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-iNSH47r3uu"
      },
      "outputs": [],
      "source": [
        "# Standard Libraries\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import random\n",
        "from typing import Optional, List\n",
        "\n",
        "# PyTorch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "# Scientific Libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computer Vision\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "\n",
        "# Wandb and Financial Data\n",
        "import wandb\n",
        "import yfinance as yf\n",
        "\n",
        "# Constants\n",
        "USE_COLAB = True\n",
        "CONTENT_DIR = \"/content\" if USE_COLAB else \".\"\n",
        "\n",
        "if not wandb.login():\n",
        "    raise ValueError(\"WandDB authentification failed.\")\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7VWYvDMNpNt"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "## Before Transformers: Sequence Modeling Challenges\n",
        "\n",
        "Before the advent of Transformers, sequence modeling tasks primarily relied on recurrent neural network (RNN) architectures, such as vanilla RNNs, LSTMs (Long Short-Term Memory networks), and GRUs (Gated Recurrent Units). These architectures were designed to process data sequentially, making them well-suited for tasks where temporal or sequential relationships are critical, such as language modeling, translation, and time-series analysis.\n",
        "\n",
        "**Strengths of RNNs, LSTMs, and GRUs:**\n",
        "- Sequential Processing: RNNs inherently model temporal dependencies by processing input data token by token.\n",
        "- Memory Mechanisms: LSTMs and GRUs improve on standard RNNs by incorporating gating mechanisms to capture long-range dependencies and mitigate the vanishing gradient problem.\n",
        "\n",
        "**Key Challenges and Limitations:**\n",
        "- Sequential Computation: The sequential nature of RNNs makes training and inference slow, as tokens must be processed in order. This limits parallelization and scalability.\n",
        "- Long-Term Dependencies: Despite improvements, capturing very long-range dependencies remains challenging. Models often fail to effectively propagate information over extended sequences.\n",
        "- Gradient Issues: RNNs can suffer from vanishing or exploding gradients, making it difficult to train deep models on long sequences.\n",
        "Fixed-Length Representations: Many traditional architectures compress variable-length sequences into fixed-size vectors, potentially losing important information.\n",
        "\n",
        "\n",
        "## The Need for a Paradigm Shift:\n",
        "\n",
        "The limitations of RNN-based architectures inspired the search for alternatives capable of:\n",
        "- Parallelizing computation for faster training and inference.\n",
        "- Handling long-range dependencies efficiently.\n",
        "- Representing sequences in a more flexible and scalable manner.\n",
        "\n",
        "This led to the development of Transformers, which utilize self-attention mechanisms to address these challenges, transforming how sequence modeling is approached.\n",
        "\n",
        "## Attention: The Core of Transformers\n",
        "\n",
        "Attention, self-attention, and multi-head attention are central to the Transformer architecture. These mechanisms enable the model to focus on the most relevant parts of the input, dynamically identifying important regions or tokens for a given task.\n",
        "- Self-Attention: Computes relationships between all tokens in the input, capturing both local and global dependencies effectively.\n",
        "- Multi-Head Attention: Extends self-attention by processing multiple subspaces simultaneously, allowing the model to focus on diverse aspects of the input (e.g., syntax, semantics).\n",
        "\n",
        "Advantages of Attention:\n",
        "- Processes tokens in parallel, enabling faster computation.\n",
        "- Captures long-range dependencies across the input.\n",
        "- Improves representational flexibility for complex relationships.\n",
        "Attention mechanisms form the backbone of the Transformer's ability to model sequences efficiently and effectively.\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "The Transformer is a neural network architecture fundamentally built on attention mechanisms. It is structured as an **encoder-decoder** framework, with distinct roles for each component:\n",
        "- **Encoder:** Maps an input sequence of symbol representations $(x_1, \\dots, x_n)$ to a sequence of intermediate representations $(z_1, \\dots, z_n)$.  \n",
        "- **Decoder:** Takes the encoder's output $z$ and generates an output sequence $(y_1, \\dots, y_m)$.  \n",
        "\n",
        "A key characteristic of the decoder is that it operates in an **auto-regressive** manner: at each time step, it uses the previously generated symbols as additional inputs to generate the next symbol in the sequence. This property ensures that the output is generated sequentially, preserving dependencies between tokens.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" width= 400>    \n",
        "<img src=\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" width= 400>\n",
        "\n",
        "# Positional Encoding\n",
        "\n",
        "Transformers operate on sequences of data where the order of elements is critical. To illustrate the importance of order, consider the following example:\n",
        "\n",
        "> Vivre pour manger â‰  Manger pour vivre.\n",
        "\n",
        "In recurrent architectures such as RNNs, LSTMs, or GRUs, the sequential nature of processing inherently captures positional information, as tokens are processed in order. However, Transformers lack this sequential mechanism due to their parallelized processing of input sequences. This raises an important question:\n",
        "\n",
        "How can we encode the positional information of tokens within the Transformer architecture?\n",
        "\n",
        "The solution proposed by the authors of the Transformer model involves incorporating positional information directly into the input embeddings. This is achieved by adding a positional encoding vector to each token's embedding. These positional encodings effectively convey the position of each token within the sequence, enabling the model to understand the relative and absolute order of tokens.\n",
        "\n",
        "Formally, the positional encoding for a token at position $pos$ and dimension $i$ is defined as:\n",
        "\n",
        "$$PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)$$\n",
        "\n",
        "$$PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)$$\n",
        "\n",
        "where:\n",
        "- $pos$ is the position of the token in the sequence.\n",
        "- $i$ refers to the dimension of the positional encoding.\n",
        "- $d_{\\text{model}}$ is the dimensionality of the model (embedding dimension).\n",
        "\n",
        "The wavelength form a geometric progression from $2\\pi$ to $10000 \\cdot 2\\pi$ across the dimensions. This function allows the model to learn representations that consider both the absolute and relative positions of tokens in the sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7QlOkOU1RY9"
      },
      "source": [
        "# 1 - Data\n",
        "\n",
        "## 1.1 Data Collection\n",
        "\n",
        "You are encouraged to download and analyze any stock data of your choice, making the learning experience both practical and customizable.\n",
        "You need table of stock data with the following columns:\n",
        "- Date\n",
        "- Open\n",
        "- High\n",
        "- Low\n",
        "- Close\n",
        "- Volume\n",
        "- Adj Close\n",
        "\n",
        "You can obtain stock data in several ways:\n",
        "- download the data from any source that provide a \"csv\"-like file\n",
        "    * S&P500 : https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC,  https://www.nasdaq.com/market-activity/index/spx/historical\n",
        "    * Bitcoin : https://finance.yahoo.com/quote/BTC-USD/history?p=BTC-USD,...\n",
        "    * Gold : https://finance.yahoo.com/quote/GC%3DF/history?p=GC%3DF,..\n",
        "- use the `yfinance` library to download the data directly from the Yahoo Finance website\n",
        "    - S&P500: \"^GSPC\"\n",
        "    - Bitcoin: \"BTC-USD\"\n",
        "    - Gold: \"GC=F\"\n",
        "\n",
        "Note: A longer historical period is essential to capture trends and train the model effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJJkRuiodYrL"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# option 2\n",
        "data_dict = {\"S&P500\":\"^GSPC\",\"Bitcoin\":\"BTC-USD\", 'Gold':\"GC=F\"}\n",
        "for key,value in data_dict.items():\n",
        "    data_dict[key]= yf.Ticker(value).history(start=\"2018-01-01\", end=\"2025-02-23\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3iWvFuGdYrL"
      },
      "source": [
        "## 1.2 - EDA: Identifying Trends in Your Stock  \n",
        "\n",
        "As a Data Scientist, the first step is to thoroughly explore the data before proceeding with modeling. This step, known as **Exploratory Data Analysis (EDA)**, is essential for understanding the data and preparing it for subsequent tasks.  \n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:862/1*bNSd-pm4XjkOV7uSTNAfnA.jpeg\" width= 400>\n",
        "\n",
        "\n",
        "**Time Series** data consists of data points indexed by time, typically organized as sequences of equally spaced intervals. In this exercise, we will explore a stock dataset to gain insights into its behavior over time.  \n",
        "\n",
        "\n",
        "**Goals of EDA**:  \n",
        "- Provide a **description of the stock** and its context.  \n",
        "- Summarize the dataset's features and their distributions.  \n",
        "- Hypothesize **potential trends for the next week** based on observed patterns.  \n",
        "- Visualize **key features** and their temporal behavior.  \n",
        "- Examine the **correlations** between features to uncover relationships.\n",
        "\n",
        "To achieve these goals, you can use various Python libraries for data manipulation and visualization:\n",
        "- [**`pandas`**](https://pandas.pydata.org/docs/index.html): For reading CSV files and data manipulation.  \n",
        "  - `read_csv()`: Reads the CSV file.  \n",
        "  - `head()`: Displays the first rows of the dataset.  \n",
        "  - `describe()`: Summarizes statistics for numerical features.\n",
        "- [**`seaborn`** ](https://seaborn.pydata.org/): For creating attractive and informative visualizations.  \n",
        "  - `displot()`: Visualizes feature distributions.  \n",
        "  - `heatmap()`: Displays correlations between features.\n",
        "- [**`matplotlib`**](https://matplotlib.org/): For basic plotting and visual analysis.  \n",
        "\n",
        "---\n",
        "\n",
        "**1. Perform Feature Summarization:**  \n",
        "- Summarize key metrics such as `Open`, `Close`, `High`, `Low`, and `Volume` using `describe()`.  \n",
        "- Identify missing values, outliers, or unusual distributions.  \n",
        "\n",
        "**2. Visualize Key Features:**  \n",
        "- Use **`matplotlib`** or **`seaborn`** to plot trends in stock prices (`Close`, `Open`) over time.  \n",
        "- Explore the distribution of features using `displot()`.  \n",
        "\n",
        "**3. Analyze Feature Correlations:**  \n",
        "- Compute correlations between numerical features (e.g., between `Volume` and `Close`).  \n",
        "- Visualize the correlation matrix using a heatmap.  \n",
        "\n",
        "**4. Hypothesize Trends:**  \n",
        "- Based on patterns in the data, make an educated guess about potential trends for the next week.\n",
        "\n",
        "**5. Formulate Hypotheses:**  \n",
        "- Use observations from the visualizations and summary statistics to hypothesize potential trends in the stock for the upcoming week. For instance, identify patterns such as steady growth, volatility, or mean-reversion tendencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz0KoIqMdYrM"
      },
      "outputs": [],
      "source": [
        "# TODO: a in depth EDA\n",
        "# 1 - Feature Summarization\n",
        "for key,value in data_dict.items():\n",
        "    data_dict[key]=pd.DataFrame(value)\n",
        "    print(\"Description of the Dataset\", key,\"\\n\", data_dict[key].describe(),\"\\n\")\n",
        "for key,value in data_dict.items():\n",
        "    print(\"Missing values in the Dataset\", key,\"\\n\", data_dict[key].isna().sum(),\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 - Visualize key features\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "for key,value in data_dict.items():\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(data_dict[key].index, data_dict[key]['Close'], label='Close')\n",
        "    plt.plot(data_dict[key].index, data_dict[key]['Open'], label='Open')\n",
        "    plt.title(f'{key} Stock Prices')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kJTcgvkhlhoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of key features :\n",
        "for key,value in data_dict.items():\n",
        "    g = sns.displot(data=data_dict[key], x=\"Close\", kde=True,)\n",
        "    g.set(title=f'Distribution of Close Price for {key}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RjV2jXLnmMVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 - Analyze feature correlations\n",
        "for key, value in data_dict.items():\n",
        "    plt.figure(figsize=(10, 8))  # Adjust figure size\n",
        "    numeric_df = value[[\"Close\", \"Open\", \"High\", \"Low\",\"Volume\"]] # Select only numeric columns\n",
        "    corr_matrix = numeric_df.corr()  # Compute correlation matrix\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title(f'Correlation Matrix for {key}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BrTpnPidpNa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Identifying Steady Growth, Volatility and Mean reversion tendencies**"
      ],
      "metadata": {
        "id": "fxVq3fFfsxCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1 - Steady Growth*"
      ],
      "metadata": {
        "id": "lgeDaA7JtII0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing 50-day and 200-day EMA\n",
        "for key, value in data_dict.items():\n",
        "  value[\"Date\"]=pd.to_datetime(value.index)\n",
        "  value.set_index(\"Date\", inplace=True)\n",
        "  value[\"EMA_50\"] = value[\"Close\"].ewm(span=50, adjust=False).mean()\n",
        "  value[\"EMA_200\"] = value[\"Close\"].ewm(span=200, adjust=False).mean()\n",
        "\n",
        "  # Plot the EMA indicators\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.plot(value.index, value[\"Close\"], label=f\" {key} Close Price\", alpha=0.6)\n",
        "  plt.plot(value.index, value[\"EMA_50\"], label=f\"{key} 50-day EMA\", alpha=0.7)\n",
        "  plt.plot(value.index, value[\"EMA_200\"], label=f\" {key} 200-day EMA\", alpha=0.7)\n",
        "  plt.legend()\n",
        "  plt.title(f\"{key} Stock Price with EMA Indicators\")\n",
        "  plt.xlabel(\"Date\")\n",
        "  plt.ylabel(\"Price\")\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L_RPeDhEtTN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions :** *We can see that the 50-day EMA curve is above the 200-day EMA curve from the end of 2023 for all our datasets, which indicates a long-term uptrend (Steady growth)*"
      ],
      "metadata": {
        "id": "I6UZufYTxB0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2 - Volatility*\n",
        "\n",
        "\n",
        "Now we will try to detect Volatility using Rolling Standard Deviation and Bollinger Bands :"
      ],
      "metadata": {
        "id": "5xHBti0rx-8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in data_dict.items():\n",
        "  value[\"Date\"]=pd.to_datetime(value.index)\n",
        "  value.set_index(\"Date\", inplace=True)\n",
        "\n",
        "  # Compute Rolling Standard Deviation (Volatility) over a 20-day window\n",
        "  value[\"Volatility\"] = value[\"Close\"].rolling(window=20).std()\n",
        "\n",
        "  # Compute Bollinger Bands (20-day SMA Â± 2 Standard Deviations)\n",
        "  value[\"SMA_20\"] = value[\"Close\"].rolling(window=20).mean()\n",
        "  value[\"Upper_Band\"] = value[\"SMA_20\"] + 2 * value[\"Volatility\"]\n",
        "  value[\"Lower_Band\"] = value[\"SMA_20\"] - 2 * value[\"Volatility\"]\n",
        "\n",
        "  # Plot Price, Bollinger Bands, and Volatility\n",
        "\n",
        "  # Price and Bollinger Bands\n",
        "  fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "  ax1.plot(value.index, value[\"Close\"], label=f\"{key} Close Price\", color=\"blue\", alpha=0.7)\n",
        "  ax1.plot(value.index, value[\"Upper_Band\"], label=f\"{key} Upper Band\", color=\"green\", alpha=0.7)\n",
        "  ax1.plot(value.index, value[\"Lower_Band\"], label=f\"{key} Lower Band\", color=\"red\", alpha=0.7)\n",
        "  ax1.fill_between(value.index, value[\"Upper_Band\"], value[\"Lower_Band\"], color=\"gray\", alpha=0.2)\n",
        "  ax1.set_ylabel(f\"{key} Price\")\n",
        "  ax1.set_title(f\"Volatility Detection with Bollinger Bands & Rolling Std Dev for {key}\")\n",
        "\n",
        "  # Volatility (Rolling Std Dev) on secondary axis\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.plot(value.index, value[\"Volatility\"], label=f\"{key} Volatility\", color=\"orange\", alpha=0.7)\n",
        "  ax2.set_ylabel(f\"{key} Volatility\")\n",
        "\n",
        "  fig.legend(loc=\"upper left\", bbox_to_anchor=(0.15, 0.85))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "vvKQD-ZgyGNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation :** *We can see that when we have wider bands tha volatility increases (Last quarter of 2020 for gold anf first quarter of 2020 for S&P500 for example). The Bollinger Bands could be a good indicator for trading operations as when the price curve touches the upper band this could mean a potential sell signal ; on the contrary when it touches the lower band this means that we're in Oversold conditions which could be a potential buy signal.*"
      ],
      "metadata": {
        "id": "r9TtZCMU-QSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*3 - Mean reversion tendencies :*\n",
        "\n",
        "We will use ADF(Augmented Dickey-Fuller) Test to determine the stationarity of our timeseries and the Z-Score of price which measures how far the price deviates from its moving average (mean-reversion signal)."
      ],
      "metadata": {
        "id": "a9H_A6oU_idt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "for key, value in data_dict.items():\n",
        "    print(f\"\\nðŸ“Š Analyzing Mean Reversion for: {key}\\n\")\n",
        "\n",
        "    # Ensure 'Date' is a datetime index\n",
        "    value[\"Date\"]=pd.to_datetime(value.index)\n",
        "    value.set_index(\"Date\", inplace=True)\n",
        "\n",
        "    # Compute 20-day Simple Moving Average (SMA)\n",
        "    value[\"SMA_20\"] = value[\"Close\"].rolling(window=20).mean()\n",
        "\n",
        "    # Compute Rolling Standard Deviation (20-day)\n",
        "    value[\"Volatility\"] = value[\"Close\"].rolling(window=20).std()\n",
        "\n",
        "    # Compute Z-Score: (Price - Mean) / Standard Deviation\n",
        "    value[\"Z-Score\"] = (value[\"Close\"] - value[\"SMA_20\"]) / value[\"Volatility\"]\n",
        "\n",
        "    # Run ADF Test\n",
        "    adf_result = adfuller(value[\"Close\"].dropna())\n",
        "\n",
        "    # Print ADF Test results\n",
        "    print(f\"ADF Test Statistic: {adf_result[0]:.3f}\")\n",
        "    print(f\"P-Value: {adf_result[1]:.3f}\")\n",
        "    print(\"Critical Values:\", adf_result[4])\n",
        "\n",
        "    if adf_result[1] < 0.05:\n",
        "        print(\"âœ… The time series is STATIONARY â†’ Likely MEAN-REVERTING.\")\n",
        "    else:\n",
        "        print(\"âŒ The time series is NON-STATIONARY â†’ No strong mean reversion.\")\n",
        "\n",
        "    # Plot Close Price & Z-Score\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Plot Price and SMA\n",
        "    ax1.plot(value.index, value[\"Close\"], label=\"Close Price\", alpha=0.6)\n",
        "    ax1.plot(value.index, value[\"SMA_20\"], label=\"20-day SMA\", linestyle=\"dashed\", color=\"orange\")\n",
        "    ax1.set_ylabel(\"Price\")\n",
        "    ax1.set_title(f\"Mean Reversion Detection for {key} using ADF Test & Z-Score\")\n",
        "\n",
        "    # Plot Z-Score on Secondary Axis\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(value.index, value[\"Z-Score\"], label=\"Z-Score\", color=\"purple\", alpha=0.6)\n",
        "    ax2.axhline(2, linestyle=\"dashed\", color=\"red\")  # Overbought threshold\n",
        "    ax2.axhline(-2, linestyle=\"dashed\", color=\"green\")  # Oversold threshold\n",
        "    ax2.set_ylabel(\"Z-Score\")\n",
        "\n",
        "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.15, 0.85))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aoDlnTm1_sdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Additional info : (Trading signal)*\n",
        "\n",
        "\n",
        "\n",
        "1.   Z-Score > 2 â†’ Overbought â†’ Price likely to revert downward (Short Opportunity ðŸš¨)\n",
        "2.   Z-Score < -2 â†’ Oversold â†’ Price likely to revert upward (Buy Opportunity âœ…)"
      ],
      "metadata": {
        "id": "WQdjLnQMDRER"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya7-5jyUqv-c"
      },
      "source": [
        "## 1.3 - Creating a Stock Dataset\n",
        "\n",
        "\n",
        "### Features\n",
        "In this section, we will process a stock dataset containing multiple features. We will focus on utilizing the **attention mechanism** to process five specific features:\n",
        "\n",
        "- **Open**\n",
        "- **High**\n",
        "- **Low**\n",
        "- **Close**\n",
        "- **Volume**\n",
        "\n",
        "### Sliding Window Approach\n",
        "\n",
        "We will use a *sliding, non-overlapping* window of size $N_{window}$ to generate input-output pairs. The input for each sequence will consist of the previous $N_{window}$ time steps, and the output will be the following $N_{window}$ time steps. Specifically, we aim to approximate the following relationship:\n",
        "\n",
        "$$\n",
        "f(W_t) \\approx W_{t+1}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$$\n",
        "W_t = (p_{t_{w}}, p_{t_{w+1}}, \\dots, p_{t_{w+N_{window}-1}})\n",
        "$$\n",
        "\n",
        "Example for $N_{window} = 3$\n",
        "\n",
        "- **Input 1**: $[p_0, p_1, p_2]$  \n",
        "  **Label 1**: $[p_3, p_4, p_5]$\n",
        "\n",
        "- **Input 2**: $[p_3, p_4, p_5]$  \n",
        "  **Label 2**: $[p_6, p_7, p_8]$\n",
        "\n",
        "- **Input 3**: $[p_6, p_7, p_8]$  \n",
        "  **Label 3**: $[p_9, p_{10}, p_{11}]$\n",
        "\n",
        "\n",
        "### Dataset class\n",
        "\n",
        "We will construct a dataset compatible with PyTorch's `Dataset` class. The custom dataset will take the following inputs:\n",
        "- **Dataframe(s)** containing the stock data.\n",
        "- **$N_{window}$**: The length of the sequence, representing the window size.\n",
        "- normalized: A boolean indicating whether to normalize the data (Min-Max scaling to [-1, 1]).\n",
        "- num_steps: The number of steps between consecutive data points. This parameter allows for the creation of sequences with a gap between each data point, enabling the model to learn from more diverse patterns.\n",
        "\n",
        "Since we are dealing with time series data, which is inherently sequential, each data point $p_{i}$ belongs to a sequence of length $N_{window}$. The goal is to predict the future behavior of the stock based on past observations.\n",
        "\n",
        "The `__getitem__` method should return a dictionary containing the following:\n",
        "- **`dict['input']`**: A list of $N_{window}$ input values.\n",
        "- **`dict['label']`**: A list of $N_{window}$ target values (the future values the model needs to predict).  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in data_dict.items():\n",
        "    data_dict[key]=data_dict[key][[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"Dividends\",\"Stock Splits\"]]\n"
      ],
      "metadata": {
        "id": "ioIlKMmXGF3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in data_dict.items():\n",
        "  print(data_dict[key].columns)"
      ],
      "metadata": {
        "id": "uASrt8aKG2gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRJG6afmrdPD"
      },
      "outputs": [],
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self, df, N_window, normalized=True, num_steps=1):\n",
        "        self.df = df\n",
        "        self.df.dropna(how=\"any\", axis=0, inplace=True)\n",
        "        self.N_window = N_window\n",
        "        self.num_steps = num_steps\n",
        "        self.normalized = normalized\n",
        "        self.X, self.y = self.process_df()\n",
        "\n",
        "    def process_df(self):\n",
        "        \"\"\"\n",
        "        process method should return X,y:\n",
        "        * X is an array of num_steps*N_windows input values\n",
        "        * y is an array of corresponding target values\n",
        "        \"\"\"\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        data_raw = self.df.to_numpy()\n",
        "        close = self.df[\"Close\"].to_numpy()\n",
        "        open = self.df[\"Open\"].to_numpy()\n",
        "        high = self.df[\"High\"].to_numpy()\n",
        "        low = self.df[\"Low\"].to_numpy()\n",
        "        volume = self.df[\"Volume\"].to_numpy()\n",
        "\n",
        "        if self.normalized:\n",
        "            close = scaler.fit_transform(close.reshape(-1, 1))\n",
        "            open = scaler.fit_transform(open.reshape(-1, 1))\n",
        "            high = scaler.fit_transform(high.reshape(-1, 1))\n",
        "            low = scaler.fit_transform(low.reshape(-1, 1))\n",
        "            volume = scaler.fit_transform(volume.reshape(-1, 1))\n",
        "        assert len(close) == len(open) == len(high) == len(low) == len(volume)\n",
        "        data_raw = np.hstack([close, open, high, low, volume])\n",
        "\n",
        "        print(data_raw.shape)\n",
        "\n",
        "        # TODO : Create a list of non-overlaping sequences of N_window elements\n",
        "        windows = []\n",
        "        for i in range(0, len(data_raw) - self.N_window - self.num_steps, self.N_window):\n",
        "            window = data_raw[i:i + self.N_window]\n",
        "            target = data_raw[i + self.num_steps : i + self.N_window + self.num_steps]\n",
        "            windows.append((window, target))\n",
        "\n",
        "\n",
        "        # TODO : Return an array of sequences where X is the input values and y the target values\n",
        "        X = np.array([window for window, _ in windows])\n",
        "        y = np.array([target for _, target in windows])\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Be careful on your len because of the overlapping issues\n",
        "        \"\"\"\n",
        "        # TODO : What is the len of the dataset ?\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        __getitem__ method should return a dictionnary where :\n",
        "        * dict['input'] : is a list of num_{steps} lists of N_{window} elements\n",
        "        * dict['label'] : is a list of N_{window} target value\n",
        "        \"\"\"\n",
        "        # TODO : Return one element\n",
        "        x = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        return {\"input\": x, \"label\": y}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4x35Ng2dYrM"
      },
      "outputs": [],
      "source": [
        "for key, value in data_dict.items():\n",
        "  df = data_dict[key]\n",
        "  N_window = 7\n",
        "  normalized = True\n",
        "  dataset = StockDataset(df, N_window, normalized)\n",
        "\n",
        "\n",
        "  assert dataset[0][\"input\"].shape == (N_window, 5)\n",
        "  assert dataset[0][\"label\"].shape == (N_window, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3zY-G3SrKxc"
      },
      "source": [
        "## 1.4 - Creating the Lightning DataModule\n",
        "\n",
        "As usual create a Lightning Datamodule that encompasses everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53MZMTbbrYRT"
      },
      "outputs": [],
      "source": [
        "class StockDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, df, N_window, normalized, batch_size):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.N_window = N_window\n",
        "        self.normalized = normalized\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage):\n",
        "        # First stage is 'fit' (or None)\n",
        "\n",
        "        # TODO : Do we shuffle the datasets ? Why ?\n",
        "        X_train, X_test = train_test_split(self.df, shuffle=True)\n",
        "        X_train, X_valid = train_test_split(X_train, shuffle=True)\n",
        "\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            # We create a validation split to watch the training.\n",
        "            # TODO : As usual\n",
        "            self.stock_train = StockDataset(X_train,self.N_window,self.normalized)\n",
        "            self.stock_valid = StockDataset(X_valid,self.N_window,self.normalized)\n",
        "\n",
        "        # Second stage is 'test'\n",
        "        if stage == \"test\" or stage is None:\n",
        "            # TODO : As usual\n",
        "            self.stock_test = StockDataset(X_test,self.N_window,self.normalized)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.stock_train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.stock_valid, self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.stock_test, self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpRHAcYNda6M"
      },
      "outputs": [],
      "source": [
        "# TODO : Initialize your datamodule\n",
        "datamodules={}\n",
        "for key, value in data_dict.items():\n",
        "  df = data_dict[key]\n",
        "  N_window = 7\n",
        "  normalized = True\n",
        "  batch_size = 32\n",
        "\n",
        "  datamodules[key]=StockDataModule(df, N_window, normalized, batch_size)\n",
        "  datamodules[key].setup(stage=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ilwKU725epE"
      },
      "source": [
        "## 2 - Positional Encoding : Incorporating Time to the features with Time2Vector\n",
        "\n",
        "As we have seen, transformers are not able to understand the order of the data.\n",
        "Usually, the original mechanism to encode the position of the data is to use a positional encoding. However, this encoding doesn't provide any sense of time.\n",
        "\n",
        "One proposed solution is to use a [Time2Vector](https://arxiv.org/abs/1907.05321) layer to encode the time information. The Time2Vector layer is a simple neural network layer that converts time into a vector representation. This vector representation can then be concatenated with the input features to provide the model with temporal information.\n",
        "\n",
        "Time2Vector is a model-agnostic vector representation for time. The main idea of this vector is that :\n",
        "* a meaningful representation of time has to include both periodic and non-periodic patterns.\n",
        "* a time representation should have an invariance to time rescaling\n",
        "\n",
        "$$ \\texttt{t2v}(\\tau)[i] =\n",
        "  \\begin{cases}\n",
        "    \\omega_i \\tau + \\varphi_i, & \\text{if~~$i=0$} \\\\\n",
        "    \\mathcal{F}(\\omega_i \\tau + \\varphi_i), & \\text{if~~$1 \\leq i \\leq k$}\n",
        "  \\end{cases} $$\n",
        "* $\\tau$ is the time (scalar)\n",
        "* $\\texttt{t2v}(\\tau)[i]$ is the i-th component of the time2vector representation of $\\tau$\n",
        "* $\\mathcal{F}$ is a periodic function for e.g. sin or cos\n",
        "* $w_i$, $\\varphi_{i}$   are learnable parameters\n",
        "\n",
        "Let's create a Time2Vec Layer. We need non-periodic feature and a periodic feature.\n",
        "* To your opinion is there a useless feature to exclude of this time embedding ?\n",
        "\n",
        "==> Yes, the non-periodic component (i = 0) could be less useful in some cases, depending on the nature of the dataset. However, we generally keep both periodic and non-periodic components in Time2Vector.\n",
        "* Why ?\n",
        "\n",
        "==> The non-periodic feature ($\\omega_0 \\tau + \\varphi_0$,) captures monotonic trends in the data (e.g., a stock price steadily increasing). However, if the dataset already has features capturing trends, this part could be redundant.\n",
        "The periodic features ($\\mathcal{sin}(\\omega_i \\tau + \\varphi_i)$) are critical because they capture seasonality and recurring patterns, which are crucial for time series data (e.g., daily or weekly cycles in stock prices).\n",
        "\n",
        "**Important Disclaimer : Usually we add our positional encoding to our input tensor. However, in our case we will concatenate it.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW3jL4sE9bDm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Time2Vector(nn.Module):\n",
        "\n",
        "  def __init__(self,in_features):\n",
        "      super().__init__()\n",
        "      self.in_features = in_features\n",
        "      self.w0 = nn.parameter.Parameter(torch.randn(1,1), requires_grad =True)\n",
        "      self.b0 = nn.parameter.Parameter(torch.randn(1), requires_grad =True)\n",
        "      self.w = nn.parameter.Parameter(torch.randn(1,1), requires_grad =True)\n",
        "      self.b = nn.parameter.Parameter(torch.randn(1), requires_grad =True)\n",
        "      self.f = torch.sin\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "      bs,seq_len,n_feat = x.shape\n",
        "      # TODO : Exclude the unwanted feature and compute the mean along the last axis\n",
        "      x = x.mean(dim=-1)\n",
        "\n",
        "      linear = x.unsqueeze(-1)\n",
        "      periodic = x.unsqueeze(-1)\n",
        "      linear = torch.matmul(linear,self.w0) + self.b0\n",
        "      W = self.w.repeat(bs,1,1)\n",
        "      b = self.b.repeat(bs,1,1)\n",
        "      periodic = self.f(torch.bmm(periodic,W) + b)\n",
        "      return torch.cat([linear, periodic], -1)\n",
        "\n",
        "# TODO : Verify the output of Time2Vector shape. It should be of shape (Batch Size, Sequence Length, 2)\n",
        "bs, seq_len, in_features = 32, 10, 5\n",
        "dummy_input = torch.randn(bs, seq_len, in_features)\n",
        "t2v_layer = Time2Vector(in_features)\n",
        "output = t2v_layer(dummy_input)\n",
        "\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0DesvfbB6wD"
      },
      "source": [
        "### III - Transformer : A Big Model around Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZIMEQz6LZ4u"
      },
      "source": [
        "We are going to build each modules of our Transformer model. The heart of the model resides in the Attention Mecanism. The goal of the Attention mecanism is to force the model to look at specific part of the input. We will build each component of the transformer part by part.\n",
        "\n",
        "\n",
        "Create the different components of the Transformer Encoder :\n",
        "* Attention Module\n",
        "* Multi-Head Attention Module\n",
        "* Transformer Encoder Layer\n",
        "* Transformer Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1bU8e0LCUiu"
      },
      "source": [
        "#### a - Attention layer\n",
        "\n",
        "Let's compute the attention layer. We will create a layer that computes Bandhanau's attention also called Dot Scale Product attention. The attention mecanism takes an input $X$ and project it using a set of queries, keys and values. Think of it as a Database which you query (with the queries) using a set of keys, which returns a set values.\n",
        "\n",
        "Mathematicaly speaking, we are computing the scaled dot product between $Q$, $K$, $V$\n",
        "\n",
        "\n",
        "The attention is :\n",
        "\n",
        "$$ \\text{Attention}(Q,K,V) =  \\text{Softmax}\\left(\\frac{Q~K^T}{\\sqrt{dim}}\\right) \\cdot  V $$\n",
        "\n",
        "<img src=\"https://production-media.paperswithcode.com/methods/SCALDE.png\" height = 400>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim_query):\n",
        "        super().__init__()\n",
        "        self.dim_query = dim_query  # Dimension of the query (and key)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        \"\"\"\n",
        "        Compute the attention mechanism.\n",
        "\n",
        "        Args:\n",
        "            q (torch.Tensor): Query tensor of shape (batch_size, num_heads, seq_len, dim_query)\n",
        "            k (torch.Tensor): Key tensor of shape (batch_size, num_heads, seq_len, dim_query)\n",
        "            v (torch.Tensor): Value tensor of shape (batch_size, num_heads, seq_len, dim_value)\n",
        "\n",
        "        Returns:\n",
        "            context (torch.Tensor): The context vector (attention-weighted sum of values)\n",
        "            attn (torch.Tensor): The attention weights (softmax of the scaled dot product)\n",
        "        \"\"\"\n",
        "        # Step 1: Reshape q, k, v to 3D tensors by merging batch_size and num_heads\n",
        "        batch_size, num_heads, seq_len, dim_query = q.shape\n",
        "        q = q.reshape(batch_size * num_heads, seq_len, dim_query)  # Shape: (batch_size * num_heads, seq_len, dim_query)\n",
        "        k = k.reshape(batch_size * num_heads, seq_len, dim_query)  # Shape: (batch_size * num_heads, seq_len, dim_query)\n",
        "        v = v.reshape(batch_size * num_heads, seq_len, v.shape[-1])  # Shape: (batch_size * num_heads, seq_len, dim_value)\n",
        "\n",
        "        # Step 2: Compute the attention scores (scaled dot product)\n",
        "        attn_scores = torch.bmm(q, k.transpose(1, 2)) / math.sqrt(self.dim_query)\n",
        "\n",
        "        # Step 3: Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Step 4: Compute the context vector as the weighted sum of the values\n",
        "        context = torch.bmm(attn_weights, v)\n",
        "\n",
        "        # Step 5: Reshape the context back to the original shape\n",
        "        context = context.reshape(batch_size, num_heads, seq_len, -1)  # Shape: (batch_size, num_heads, seq_len, dim_value)\n",
        "\n",
        "        return context, attn_weights\n"
      ],
      "metadata": {
        "id": "nm3Zeda4EIVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q24Z5fwECRji"
      },
      "source": [
        "#### b - Multi head Attention\n",
        "\n",
        "Usually, we like creating a Multi-Head Attention layer. Multi-Head only means that we are computing the attention over multiple heads. In fact, instead of having only one function computed by the attention mecanism, we leave each head free to learn a different function. Hence, we will have different outputs each computing a different value.\n",
        "\n",
        "Mathematically speaking :\n",
        "\n",
        "$MultiHead(Q,K,V)=Concat(head_1,â€¦,head_h)W^O$\n",
        "\n",
        "with $head_i=Attention(QW_i^Q,KW_i^K,VW_i^V).$\n",
        "\n",
        "\n",
        "<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTv6Bgq7bdnXdT-JDWEnnzK2EM1xY0NUEOyBg&usqp=CAU'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asj6n9anTZ0j"
      },
      "source": [
        " Question :    \n",
        " * What is $W^O$ ? Is it a learned parameter ?\n",
        "\n",
        "\n",
        "In the multi-head attention mechanism, multiple attention heads operate in parallel, each learning different attention patterns by using independent weight matrices $( W_i^Q, W_i^K, W_i^V )$. Once the attention outputs from all heads are computed, they are concatenated and passed through a learnable projection matrix $ W^O $.\n",
        "\n",
        "Yes, $ W^O $ is a learned parameter. Its role is to transform the concatenated outputs of different heads into the desired final representation, ensuring that the model effectively integrates the diverse attention patterns captured by each head. By learning $ W^O $, the model can adaptively combine information from multiple perspectives, improving its ability to capture both local and global dependencies within the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq70X8FLDyR2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, dim_query, dim_value, num_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Linear layers to project input tensors into multiple heads\n",
        "        self.w_query = nn.Linear(embed_dim, num_heads * dim_query)\n",
        "        self.w_key = nn.Linear(embed_dim, num_heads * dim_query)\n",
        "        self.w_value = nn.Linear(embed_dim, num_heads * dim_value)\n",
        "\n",
        "        # Linear layer to combine the multi-head outputs\n",
        "        self.linear = nn.Linear(num_heads * dim_value, embed_dim)\n",
        "\n",
        "        # Attention layer that we will reuse for each head\n",
        "        self.attention = Attention(dim_query)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"\"\"\n",
        "        Compute the multi-head attention.\n",
        "\n",
        "        Args:\n",
        "            query (torch.Tensor): Query tensor of shape (batch_size, seq_len, embed_dim)\n",
        "            key (torch.Tensor): Key tensor of shape (batch_size, seq_len, embed_dim)\n",
        "            value (torch.Tensor): Value tensor of shape (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        Returns:\n",
        "            attn (torch.Tensor): Attention weights after linear transformation\n",
        "            context (torch.Tensor): The context vector after multi-head attention\n",
        "        \"\"\"\n",
        "        # Project the query, key, and value tensors into their respective heads\n",
        "        q = self.w_query(query).view(query.size(0), query.size(1), self.num_heads, self.head_dim)\n",
        "        k = self.w_key(key).view(key.size(0), key.size(1), self.num_heads, self.head_dim)\n",
        "        v = self.w_value(value).view(value.size(0), value.size(1), self.num_heads, self.head_dim)\n",
        "\n",
        "        # Permute to get the shape (batch_size, num_heads, seq_len, head_dim)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k = k.permute(0, 2, 1, 3)\n",
        "        v = v.permute(0, 2, 1, 3)\n",
        "\n",
        "        # Compute the attention for each head\n",
        "        context, attn_weights = self.attention(q, k, v)\n",
        "\n",
        "        # Reshape the context to combine all heads\n",
        "        context = context.permute(0, 2, 1, 3).contiguous().view(query.size(0), query.size(1), self.num_heads * self.head_dim)\n",
        "\n",
        "        # Apply the final linear layer to get the output of multi-head attention\n",
        "        attn_output = self.linear(context)\n",
        "\n",
        "        return attn_output, attn_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9L27Af1C98Y"
      },
      "source": [
        "#### c - Transforming the Transformer\n",
        "\n",
        "So let's create our Transformer model. We will just create the Encoder, as we don't need the Decoder in our case. We are just trying to Encode the input and find interesting patterns.\n",
        "Usually we code the Transformer Model into a specific format :\n",
        "* Layer Class\n",
        "* Model Class\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm\" height=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSo7KRdQPkhS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        dim_query,\n",
        "        dim_value,\n",
        "        num_heads,\n",
        "        dim_feedforward=256,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(embed_dim, dim_query, dim_value, num_heads)\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(embed_dim, dim_feedforward),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim_feedforward, embed_dim),\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        q = k = v = sequence\n",
        "\n",
        "        # Compute the multi-head attention\n",
        "        attn, context = self.attention(q, k, v)\n",
        "\n",
        "        # Residual connection followed by layer normalization\n",
        "        sequence = sequence + self.dropout1(attn)\n",
        "        sequence = self.norm1(sequence)\n",
        "\n",
        "        # Feed-forward network\n",
        "        sequence = self.linear(sequence)\n",
        "\n",
        "        # Residual connection followed by layer normalization\n",
        "        sequence = sequence + self.dropout2(sequence)\n",
        "        sequence = self.norm2(sequence)\n",
        "\n",
        "        return sequence\n",
        "\n",
        "# Helper function to clone the layers\n",
        "def _get_clones(module, num_layers):\n",
        "    return nn.ModuleList([module for _ in range(num_layers)])\n",
        "\n",
        "# Transformer Encoder\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, encoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        # Changed permute to reshape for batch processing\n",
        "        output = sequence.reshape(sequence.size(0), sequence.size(1), -1)\n",
        "        for layer in self.layers:\n",
        "            output = layer(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWa6gmqVPoM"
      },
      "source": [
        "#### Building the entire model\n",
        "\n",
        "Finally let's build the entire model. Let's use Pytorch-Lightning to encompass everything.\n",
        "Normally your model must be composed of three components :\n",
        "* The Transformer\n",
        "* The Time2Vector\n",
        "* A Regression Head\n",
        "\n",
        "As usual ask yourself what task you are performing, how your data should travle trhough the model, what the data is, blablablablalablba\n",
        "\n",
        "Don't forget to use your favorite logger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M5xOk8FVXtN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from torch import optim\n",
        "\n",
        "class StockModel(pl.LightningModule):\n",
        "    def __init__(self, embed_dim, dim_query, dim_value, num_layers, num_heads, input_size):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "\n",
        "        # Define the Transformer Encoder Layer\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            embed_dim=embed_dim,\n",
        "            dim_query=dim_query,\n",
        "            dim_value=dim_value,\n",
        "            num_heads=num_heads,\n",
        "            dim_feedforward=256,\n",
        "            dropout=0.1\n",
        "        )\n",
        "\n",
        "        # Initialize the Transformer\n",
        "        self.transformer = TransformerEncoder(encoder_layer=encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Regression head (linear layer after the transformer)\n",
        "        self.head = nn.Linear(embed_dim, 5)\n",
        "\n",
        "        # Time2Vector Embeddings\n",
        "        self.timeencoder = Time2Vector(in_features=embed_dim)\n",
        "\n",
        "        # Initialize w0 and b0 (ensure they are on the correct device)\n",
        "        self.w0 = nn.Parameter(torch.randn(1))\n",
        "        self.b0 = nn.Parameter(torch.randn(1))\n",
        "\n",
        "        # Input projection layer to match embed_dim\n",
        "        self.input_projection = nn.Linear(input_size, embed_dim)\n",
        "\n",
        "        # Define the MSE Loss function\n",
        "\n",
        "        self.loss_fn = nn.MSELoss()  # MSELoss defaults to float32\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.type(torch.float32)\n",
        "        device = x.device\n",
        "\n",
        "        # Ensure that w0 and b0 are on the same device as the input tensor\n",
        "        self.w0 = self.w0.to(device)\n",
        "        self.b0 = self.b0.to(device)\n",
        "\n",
        "        bs, seq_len, _ = x.shape\n",
        "\n",
        "        # Get the time vector with correct sequence length\n",
        "        time_vec = self.timeencoder(x)\n",
        "\n",
        "        # Concatenate time embedding along the feature dimension\n",
        "        x = torch.cat((x, time_vec), dim=-1)\n",
        "\n",
        "        # Project the input to match embed_dim before passing to the Transformer\n",
        "        x = self.input_projection(x)\n",
        "\n",
        "\n",
        "\n",
        "        # Pass through the transformer\n",
        "        x = self.transformer(x)\n",
        "\n",
        "\n",
        "        # Ensure all tensors are on the same device\n",
        "        linear = self.w0 * torch.ones(bs, seq_len, 1, device=device) + self.b0\n",
        "        periodic = torch.sin(self.w0 * x.type(torch.float32)).to(device)\n",
        "\n",
        "        # Combine linear and periodic components\n",
        "        x = linear + periodic\n",
        "\n",
        "\n",
        "        # Flatten for the regression head\n",
        "        x = x.view(-1, x.shape[-1])  # Shape: (bs * seq_len, embed_dim)\n",
        "\n",
        "\n",
        "        # Pass through regression head\n",
        "        x = self.head(x)  # Shape: (bs * seq_len, 1)\n",
        "\n",
        "\n",
        "        # Reshape to match desired output\n",
        "        x = x.view(bs, seq_len, -1)  # Shape: (bs, seq_len, 1)\n",
        "        x = x.squeeze(-1)  # Remove the last dimension to get (bs, seq_len)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Set up the optimizer, using Stochastic Gradient Descent with momentum\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch[\"input\"].type(torch.float32).to(device)\n",
        "        y = batch[\"label\"].type(torch.float32).to(device)\n",
        "        out = self(x)\n",
        "        loss = self.loss_fn(out, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = batch[\"input\"].type(torch.float32).to(device)\n",
        "        y = batch[\"label\"].type(torch.float32).to(device)\n",
        "        out = self(x)  # Forward pass\n",
        "        loss = self.loss_fn(out, y)  # Calculate MSE Loss\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x = batch[\"input\"].type(torch.float32).to(device)\n",
        "        y = batch[\"label\"].type(torch.float32).to(device)\n",
        "        out = self(x)  # Forward pass\n",
        "        loss = self.loss_fn(out, y)  # Calculate MSE Loss\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return {\"test_loss\": loss}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNs5inW6Xt_a"
      },
      "source": [
        "## IV - Training the Model\n",
        "\n",
        "* Initialize a model with 3 stacks of Encoder with 8 heads.\n",
        "* What is the Embed Dimension ?\n",
        "* What is the Dimension of a Query, Key and Value ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HXr5PLUXupy"
      },
      "outputs": [],
      "source": [
        "# TODO : Initalize Model, Datamodule and Trainer\n",
        "embed_dim = 256\n",
        "num_heads = 8\n",
        "dim_query = embed_dim // num_heads\n",
        "dim_value = embed_dim // num_heads\n",
        "num_layers = 3\n",
        "input_size = 7\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = StockModel(\n",
        "    embed_dim=embed_dim, dim_query= dim_query, dim_value= dim_value, num_layers=num_layers, num_heads=num_heads,input_size=input_size\n",
        ").to(device)\n",
        "\n",
        "datamodules={}\n",
        "trainers={}\n",
        "for key, value in data_dict.items():\n",
        "  df = data_dict[key]\n",
        "  N_window = 10\n",
        "  normalized = True\n",
        "  batch_size = 32\n",
        "\n",
        "  datamodules[key]=StockDataModule(df, N_window, normalized, batch_size)\n",
        "\n",
        "  trainers[key] = pl.Trainer(\n",
        "    max_epochs=100,  # Number of epochs\n",
        "    precision=32,\n",
        "    devices=1,  # Use all available devices (GPUs or CPUs)\n",
        "    accelerator=\"auto\",\n",
        "    enable_progress_bar=True)\n",
        "\n",
        "  # Fit the model to the data\n",
        "\n",
        "  trainers[key].fit(model, datamodules[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_21I4eFCTqtH"
      },
      "source": [
        "## V - Testing the model : Inference\n",
        "\n",
        "Now that the model is trained, testing it is a key to become rich."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h70XsCUhZWdr"
      },
      "source": [
        "#### a - Testings\n",
        "\n",
        "Test the model on the test dataset.\n",
        "\n",
        "* What happens ?\n",
        "* What can we do to enhance the results ?\n",
        "* Will you deploy the model ?\n",
        "* What are your predictions for next week ? Can we invest or not ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LemCOfzERLZ"
      },
      "outputs": [],
      "source": [
        "for key,value in datamodules.items():\n",
        "  print(f\"\\nTest loss for {key} : \")\n",
        "  trainers[key].test(model, datamodules[key])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}